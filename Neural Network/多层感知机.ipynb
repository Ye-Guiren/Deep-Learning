{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65568553-465d-4040-af83-eb37da579af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "# 用于数据预处理和转换\n",
    "import torch.nn as nn\n",
    "# 构建神经网络模型的模块\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd1993a9-029c-4bd0-9a89-3db33884be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = \"data/mnist\",\n",
    "    # 数据存储路径\n",
    "    train = True,\n",
    "    # 加载训练集\n",
    "    transform = transforms.ToTensor(),\n",
    "    # 将数据转换为张量\n",
    "    download = True\n",
    "    # 若数据不存在则下载\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = \"data/mnist\",\n",
    "    train = False,\n",
    "    # 加载测试集\n",
    "    transform = transforms.ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284f31ab-3e0d-4ed7-82ee-a4956673437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle=True)\n",
    "# torch.utils.data.DataLoader：用于将数据集包装成可迭代的批量数据\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle=False)\n",
    "# 训练集每次用epoch打乱数据顺序：增加数据随机性\n",
    "# 测试集不打乱顺序：保持测试数据顺序稳定，便于评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf276ccb-221b-4be8-bf51-f1b4410ae416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "# 定义MLP类,继承自nn.Module,使MLP具备神经网络的基本功能\n",
    "# nn.Module:Pytorch中所有神经网络模型的基类\n",
    "    def __init__(self, input_size,hidden_size,num_classes):\n",
    "        # input_size:输入数据的维度\n",
    "        # hidden_size：隐藏层的神经元数量\n",
    "        # num_classes:输出分类的数量\n",
    "        super(MLP,self).__init__()\n",
    "        # 调用父类初始化方法\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
    "        # 第一个全连接层，输入维度 -> 隐藏层维度\n",
    "        self.relu = nn.ReLU()\n",
    "        # 定义ReLu激活函数，引入非线性\n",
    "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
    "        # 第二个全连接层，隐藏层 -> 隐藏层\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        # 第三个全连接层，隐藏层 -> 输出类别数\n",
    "# nn.Linear:定义全连接层，参数为输入维度和输出维度\n",
    "# super(MLP, self).__init__():必修调用父类初始化，确保模型正确继承nn.Module的功能\n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        # 第一层运算\n",
    "        out = self.relu(out)\n",
    "        # 对第一层的输出应用ReLU激活函数\n",
    "        out = self.fc2(out)\n",
    "        # 激活后的结果传入第二层全连接层\n",
    "        out = self.relu(out)\n",
    "        # 对第二层输出再次应用ReLU激活\n",
    "        out = self.fc3(out)\n",
    "        # 最后传入第三层全连接层，输出结果用于分类\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bf0da35-502f-42ac-8243-2d20521c8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 512\n",
    "# 隐藏层神经元数量为512,用于特征提取和特征转换\n",
    "num_classes = 10\n",
    "model = MLP(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "450f3ef8-5b48-4e91-866e-b8f2ed706d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# 定义交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b91d239-8e68-4c95-a1e4-ef45da78a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# 设置学习率\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
    "# 使用Adam优化器，能够自适应调整各参数的学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "775581d8-50d6-4bb0-9985-b40cb8cd81d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10], Step[100/600], Loss:0.2046\n",
      "Epoch[1/10], Step[200/600], Loss:0.1341\n",
      "Epoch[1/10], Step[300/600], Loss:0.1953\n",
      "Epoch[1/10], Step[400/600], Loss:0.1062\n",
      "Epoch[1/10], Step[500/600], Loss:0.1166\n",
      "Epoch[1/10], Step[600/600], Loss:0.0838\n",
      "Epoch[2/10], Step[100/600], Loss:0.1574\n",
      "Epoch[2/10], Step[200/600], Loss:0.0855\n",
      "Epoch[2/10], Step[300/600], Loss:0.0668\n",
      "Epoch[2/10], Step[400/600], Loss:0.1025\n",
      "Epoch[2/10], Step[500/600], Loss:0.0551\n",
      "Epoch[2/10], Step[600/600], Loss:0.0845\n",
      "Epoch[3/10], Step[100/600], Loss:0.0748\n",
      "Epoch[3/10], Step[200/600], Loss:0.0768\n",
      "Epoch[3/10], Step[300/600], Loss:0.0409\n",
      "Epoch[3/10], Step[400/600], Loss:0.0642\n",
      "Epoch[3/10], Step[500/600], Loss:0.0273\n",
      "Epoch[3/10], Step[600/600], Loss:0.0495\n",
      "Epoch[4/10], Step[100/600], Loss:0.0113\n",
      "Epoch[4/10], Step[200/600], Loss:0.0453\n",
      "Epoch[4/10], Step[300/600], Loss:0.0153\n",
      "Epoch[4/10], Step[400/600], Loss:0.0051\n",
      "Epoch[4/10], Step[500/600], Loss:0.1319\n",
      "Epoch[4/10], Step[600/600], Loss:0.1750\n",
      "Epoch[5/10], Step[100/600], Loss:0.0076\n",
      "Epoch[5/10], Step[200/600], Loss:0.0555\n",
      "Epoch[5/10], Step[300/600], Loss:0.0266\n",
      "Epoch[5/10], Step[400/600], Loss:0.0095\n",
      "Epoch[5/10], Step[500/600], Loss:0.0353\n",
      "Epoch[5/10], Step[600/600], Loss:0.0202\n",
      "Epoch[6/10], Step[100/600], Loss:0.0020\n",
      "Epoch[6/10], Step[200/600], Loss:0.0572\n",
      "Epoch[6/10], Step[300/600], Loss:0.0386\n",
      "Epoch[6/10], Step[400/600], Loss:0.0400\n",
      "Epoch[6/10], Step[500/600], Loss:0.0180\n",
      "Epoch[6/10], Step[600/600], Loss:0.0290\n",
      "Epoch[7/10], Step[100/600], Loss:0.0106\n",
      "Epoch[7/10], Step[200/600], Loss:0.0015\n",
      "Epoch[7/10], Step[300/600], Loss:0.0209\n",
      "Epoch[7/10], Step[400/600], Loss:0.0417\n",
      "Epoch[7/10], Step[500/600], Loss:0.0055\n",
      "Epoch[7/10], Step[600/600], Loss:0.0197\n",
      "Epoch[8/10], Step[100/600], Loss:0.0160\n",
      "Epoch[8/10], Step[200/600], Loss:0.0011\n",
      "Epoch[8/10], Step[300/600], Loss:0.0072\n",
      "Epoch[8/10], Step[400/600], Loss:0.0308\n",
      "Epoch[8/10], Step[500/600], Loss:0.0041\n",
      "Epoch[8/10], Step[600/600], Loss:0.0255\n",
      "Epoch[9/10], Step[100/600], Loss:0.0033\n",
      "Epoch[9/10], Step[200/600], Loss:0.0016\n",
      "Epoch[9/10], Step[300/600], Loss:0.0126\n",
      "Epoch[9/10], Step[400/600], Loss:0.0021\n",
      "Epoch[9/10], Step[500/600], Loss:0.0186\n",
      "Epoch[9/10], Step[600/600], Loss:0.0025\n",
      "Epoch[10/10], Step[100/600], Loss:0.0359\n",
      "Epoch[10/10], Step[200/600], Loss:0.0002\n",
      "Epoch[10/10], Step[300/600], Loss:0.0265\n",
      "Epoch[10/10], Step[400/600], Loss:0.0475\n",
      "Epoch[10/10], Step[500/600], Loss:0.0124\n",
      "Epoch[10/10], Step[600/600], Loss:0.0016\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "# 设置训练轮数\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "    # 通过数据加载其train_loader按批次获取图像和标签\n",
    "        images = images.reshape(-1,28*28)\n",
    "        # 将图像数据从二维(28*28)展平成一维(784,),以匹配模型输入维度(input_size = 28*28)\n",
    "        outputs = model(images)\n",
    "        # 将图像输入模型，进行前向传播\n",
    "        loss = criterion(outputs,labels)\n",
    "        # 使用交叉熵损失函数计算预测输出与真实标签间的损失\n",
    "        optimizer.zero_grad()\n",
    "        # 清空优化器中的梯度，避免梯度累积影响训练\n",
    "        loss.backward()\n",
    "        # 反向传播，根据损失计算模型各个参数的梯度\n",
    "        optimizer.step()\n",
    "        # 优化器根据计算的梯度更次年模型参数，完成一次参数迭代\n",
    "        if(i + 1)% 100 == 0:\n",
    "            print(f'Epoch[{epoch + 1}/{num_epochs}], Step[{i + 1}/{len(train_loader)}], Loss:{loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f479d63-0f4c-4cf7-aa4e-722c2006001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images:98.22%\n"
     ]
    }
   ],
   "source": [
    " with torch.no_grad():\n",
    "# 关闭梯度计算,测试阶段无需反向传播,减少内存消耗\n",
    "    correct = 0\n",
    "    # 记录预测正确的样本数\n",
    "    total = 0\n",
    "    # 记录总样本数\n",
    "    for images, labels in test_loader:\n",
    "         images = images.reshape(-1, 28 * 28)\n",
    "         outputs = model(images)\n",
    "         _,predicted = torch.max(outputs.data,1)\n",
    "         # 返回每行最大值的索引predicted\n",
    "         total += labels.size(0)\n",
    "         correct += (predicted == labels).sum().item()\n",
    "    print (f'Accuracy of the network on the 10000 test images:{100*correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5dc09b-8d9d-485d-94a4-413dc63ee673",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25800699-1492-4d4b-bb53-e75c4a0426ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"mnist_m;p_model.pk1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
